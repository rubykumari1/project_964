{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyPuIVRwPIz/TU8npmWLt2S/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rubykumari1/project_964/blob/main/Brat_2020_AI_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ezD2fz-JZf-c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "mmvMMWXEY7PZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82c8a591-8b2d-4a75-9cf0-d5d7b8f21d63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#Access to datasets uploaded to google Drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "import pathlib\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Environment setup - nibabel for reading NIFTI and tqdm for progress\n",
        "!pip install -q nibabel tqdm"
      ],
      "metadata": {
        "id": "dMdnn1jWZWJU"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing core libraries\n",
        "import pathlib, torch, numpy as np, albumentations as A\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import time, json, pathlib, shutil, numpy as np, nibabel as nib\n",
        "from tqdm import tqdm\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(\"GPU:\", torch.cuda.get_device_name(0))"
      ],
      "metadata": {
        "id": "rzwSxdcyZEnc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9983ca8b-1bab-4b0d-8ebc-d6a9f530f61f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU: NVIDIA A100-SXM4-40GB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Project path constants\n",
        "\n",
        "DATA_ROOT = pathlib.Path(\n",
        "    \"/content/drive/MyDrive/964_project/segmentation/\"\n",
        "    \"BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData\"\n",
        ")\n",
        "PROJ_ROOT = pathlib.Path(\"/content/drive/MyDrive/964_project/segmentation\")\n",
        "SLICE_DIR = PROJ_ROOT / \"4modslices\" #This path save the mod slices\n",
        "\n"
      ],
      "metadata": {
        "id": "H5IJNkCBZMy3"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "KEEP_ONLY_TUMOR = True tells the script to discard every axial slice whose mask is entirely background, which cuts down disk usage and training time while preventing the model from being flooded with “all-zero” examples that encourage a trivial background-only prediction.\n",
        "TUMOR_PIX_THRESH = 0.01 keeps a slice only if at least 1 % of its pixels are labeled as tumour; this keeps peripheral slices that still contain useful tumour context, but drops slices where stray mislabeled pixels would add noise.\n",
        "RESIZE_TO = None is a placeholder that lets you optionally downsample slices to a fixed resolution (for example 128×128) later on, so you can trade a little spatial detail for lower GPU memory use and more consistent input shapes without hard-coding it upfront."
      ],
      "metadata": {
        "id": "BA03itPtbkig"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "KEEP_ONLY_TUMOR = True # no blank slces skip it i.e to discard every axial slice whose mask is entirely background,\n",
        "TUMOR_PIX_THRESH = 0.01 #keeps a slice only if at least 1 % of its pixels are labeled as tumour\n",
        "RESIZE_TO = None #downsample slices to a fixed resolution (for example 128×128)"
      ],
      "metadata": {
        "id": "DNIQOsmLbqoZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The loop creates five sub-directories inside SLICE_DIR—one each for the four MRI modalities (t1, t1ce, t2, flair) and one for the segmentation mask, making sure they exist before any files are written.\n",
        "Next, the code defines a path called processed_flag that points to processed.json, a bookkeeping file stored in the same directory. If that JSON file is already present, it is read and parsed into a Python set named done_patients; each entry records a patient that has been sliced and saved earlier. Finally, the script prints how many patient folders will be skipped this run, so it won’t redo work that’s already finished."
      ],
      "metadata": {
        "id": "RKEPXV_ScVia"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#cereating 5 subdirectories inside SLICE_DIR for 4 modalities (t1, t1ce, t2, flair) and 1 for the segmenation mask\n",
        "for sub in [\"t1\",\"t1ce\",\"t2\",\"flair\",\"mask\"]:\n",
        "    (SLICE_DIR / sub).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "processed_flag = SLICE_DIR / \"processed.json\"\n",
        "\n",
        "#a set done_patients to keep record of patients\n",
        "done_patients  = set()\n",
        "if processed_flag.exists():\n",
        "    done_patients = set(json.loads(processed_flag.read_text()))\n",
        "    #will skip previously processed patients\n",
        "print(\"Will skip\", len(done_patients), \"previously-processed patients\") #each entry records a patient that has been sliced and saved earlier"
      ],
      "metadata": {
        "id": "In-KaWQxcYFL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#check the raw Niftis shold be 369\n",
        "patient_folders = sorted(DATA_ROOT.glob(\"BraTS20_Training_*\" ))\n",
        "print(\"Total patients found :\", len(patient_folders))\n",
        "\n",
        "#the first three patients\n",
        "#it then builds a dictionary whose keys are the four MRI modalities t1, t1ce, t2, flair plus the segmentation label\n",
        "#each mapping to the matching .nii file path inside that patients folder.\n",
        "#Using nibabel it loads each volume, converts it to a NumPy array, records the array’s shape, and finally prints shapes\n",
        "\n",
        "for folder in patient_folders[:3]:\n",
        "\n",
        "    vols = {m:list(folder.glob(f\"*_{m}.nii*\")) for m in\n",
        "            [\"t1\",\"t1ce\",\"t2\",\"flair\",\"seg\"]}\n",
        "\n",
        "    shapes = []\n",
        "    for m, paths in vols.items():\n",
        "        img = nib.load(str(paths[0])); arr = img.get_fdata()\n",
        "        shapes.append(arr.shape)\n",
        "        print(m, arr.shape)\n",
        "    print(folder.name, \"shapes \", shapes[0])"
      ],
      "metadata": {
        "id": "VcDYENskd08H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#zscore standard-normalises a 3-D volume\n",
        "def zscore(volume):\n",
        "    mu, sigma = volume.mean(), volume.std()\n",
        "    return (volume - mu) / (sigma + 1e-8) #1e-8 to prevent division by zero\n",
        "\n",
        "#writes a given 2-D NumPy array to disk as a .npy file | float32\n",
        "def save_slice(arr, out_path):\n",
        "    np.save(out_path.with_suffix(\".npy\"), arr.astype(np.float32))\n",
        "\n",
        "def slice_indices(mask_3d):\n",
        "    \"\"\"Return axialindices to keep ->\n",
        "\n",
        "    based on tumor-pixel %\"\"\"\n",
        "\n",
        "    if not KEEP_ONLY_TUMOR:\n",
        "\n",
        "        return range(mask_3d.shape[2])\n",
        "\n",
        "    nz_per_slice = (mask_3d > 0).sum(axis=(0,1)) #TUMOR_PIX_THRESH >0.1\n",
        "\n",
        "    keep = np.where(nz_per_slice > TUMOR_PIX_THRESH*mask_3d[:,:,0].size)[0]\n",
        "    return keep"
      ],
      "metadata": {
        "id": "i7DIfztreJEI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# check one patient/one slice\n",
        "\"\"\"\n",
        "It loads all four MRI modalities and the segmentation mask for a chosen patient,\n",
        "converts them to NumPy arrays, and counts how many tumour voxels appear in each axial slice.\n",
        "If no slice contains tumour it simply picks the middle slice!\n",
        "otherwise it selects the slice with the highest tumour-pixel count.\n",
        "It then renders a six-panel figure: the four raw modalities, the mask alone, and an overlay of the mask on T1-CE,\n",
        "so to confirm that the modalities align spatially and that the mask labels match the anatomy.\n",
        "Finally it prints which slice index was displayed.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def show_sample(patient_folder):\n",
        "\n",
        "    vols = {m:nib.load(str(list(patient_folder.glob(f\"*_{m}.nii*\"))[0]))\n",
        "            for m in [\"t1\",\"t1ce\",\"t2\",\"flair\",\"seg\"]}\n",
        "\n",
        "    vols = {k: v.get_fdata().astype(np.float32) for k,v in vols.items()}\n",
        "\n",
        "\n",
        "    nz_per_slice = (vols[\"seg\"] > 0).sum(axis=(0,1))\n",
        "    if nz_per_slice.max() == 0:\n",
        "        z = vols[\"seg\"].shape[2] // 2\n",
        "    else:\n",
        "        z = int(np.argmax(nz_per_slice))\n",
        "\n",
        "    titles = [\"T1\", \"T1-CE\", \"T2\", \"FLAIR\", \"Mask\", \"T1-CE + Mask\"]\n",
        "    imgs   = [vols[\"t1\"][:,:,z], vols[\"t1ce\"][:,:,z], vols[\"t2\"][:,:,z],\n",
        "              vols[\"flair\"][:,:,z], vols[\"seg\"][:,:,z]]\n",
        "\n",
        "    plt.figure(figsize=(15,3))\n",
        "    for i, img in enumerate(imgs):\n",
        "        plt.subplot(1,6,i+1\n",
        "        plt.imshow(img.T, cmap='gray', origin='lower')\n",
        "        plt.axis('off'); plt.title(titles[i])\n",
        "    # overlay\n",
        "    plt.subplot(1,6,6)\n",
        "    plt.imshow(vols[\"t1ce\"][:,:,z].T, cmap='gray', origin='lower')\n",
        "    plt.imshow(vols[\"seg\"][:,:,z].T, alpha=0.35, cmap='Reds', origin='lower')\n",
        "    plt.axis('off'); plt.title(titles[5])\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    print(f\"Displayed slice z={z} from {patient_folder.name}\")\n",
        "\n",
        "#check it on the first patient\n",
        "show_sample(patient_folders[0])\n"
      ],
      "metadata": {
        "id": "QAP_3xr6fzmD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#load → normalise → slice → save\n",
        "\n",
        "\"\"\"\n",
        "The loop walks through every BraTS patient folder, skips any already listed in processed.json,\n",
        "and only processes cases that contain all five required NIfTI files t1, t1ce, t2, flair, seg.\n",
        "For each complete case it z-scores the four modalities, keeps axial slices whose masks contain at least 1 % tumour pixels,\n",
        "saves those slices (and their mask) as .npy files in modality-specific sub-folders,\n",
        "and logs the patient as finished so the run can resume safely if interrupted.\n",
        "\n",
        "t1 1\n",
        "t1ce 1\n",
        "t2 1\n",
        "flair 1\n",
        "seg 0\n",
        "\n",
        "\"\"\"        |\n",
        "\n",
        "start_all = time.time()\n",
        "for folder in tqdm(patient_folders, desc=\"Patients\"):\n",
        "    pid = folder.name\n",
        "    if pid in done_patients: continue\n",
        "\n",
        "    #skip if any missing Brats 355 ----------\n",
        "    paths = {}\n",
        "    missing = []\n",
        "    for m in [\"t1\",\"t1ce\",\"t2\",\"flair\",\"seg\"]:\n",
        "        files = list(folder.glob(f\"*_{m}.nii*\"))\n",
        "        if files:\n",
        "            paths[m] = files[0]\n",
        "        else:\n",
        "            missing.append(m)\n",
        "    if missing:\n",
        "        print(f\"[WARN] {pid}: missing {missing} → skipped\")\n",
        "        done_patients.add(pid)\n",
        "        processed_flag.write_text(json.dumps(sorted(done_patients)))\n",
        "        continue\n",
        "\n",
        "    t0 = time.time()\n",
        "    paths = {m:list(folder.glob(f\"*_{m}.nii*\"))[0] for m in\n",
        "             [\"t1\",\"t1ce\",\"t2\",\"flair\",\"seg\"]}\n",
        "    vols  = {m:nib.load(str(p)).get_fdata().astype(np.float32)\n",
        "             for m,p in paths.items()}\n",
        "\n",
        "    # z-score the four imaging modalities (leave mask unchanged)\n",
        "    for m in [\"t1\",\"t1ce\",\"t2\",\"flair\"]:\n",
        "        vols[m] = zscore(vols[m])\n",
        "\n",
        "    # select slice indices\n",
        "    keep_z = slice_indices(vols[\"seg\"])\n",
        "    if len(keep_z) == 0:                # should never happen\n",
        "        print(\"No tumor slices in\", pid)\n",
        "        continue\n",
        "\n",
        "      \"\"\"\n",
        "      The data become 2-D at the save_slice(..., vols[\"t1\"][:,:,z]) here each 3-D volume is indexed [:,:,z] to grab a single axial slice before saving\n",
        "\n",
        "      \"\"\"\n",
        "\n",
        "    # iterate slices\n",
        "    for z in keep_z:\n",
        "        tag = f\"{pid}_z{z:03d}\"\n",
        "        save_slice(vols[\"t1\"]   [:,:,z], SLICE_DIR / \"t1\"   / tag)\n",
        "        save_slice(vols[\"t1ce\"] [:,:,z], SLICE_DIR / \"t1ce\" / tag)\n",
        "        save_slice(vols[\"t2\"]   [:,:,z], SLICE_DIR / \"t2\"   / tag)\n",
        "        save_slice(vols[\"flair\"][:,:,z], SLICE_DIR / \"flair\"/ tag)\n",
        "        np.save((SLICE_DIR / \"mask\" / tag).with_suffix(\".npy\"),\n",
        "                vols[\"seg\"][:,:,z].astype(np.uint8))\n",
        "\n",
        "    #record\n",
        "    done_patients.add(pid)\n",
        "    processed_flag.write_text(json.dumps(sorted(done_patients)))\n",
        "\n",
        "    print(f\"{pid}: kept {len(keep_z)} slices | \"\n",
        "          f\"time {time.time()-t0:.1f} s\")\n",
        "\n",
        "print(\"=== Finished all patients in\",\n",
        "      time.time()-start_all, \"seconds ===\")\n"
      ],
      "metadata": {
        "id": "-JkXV2Zkhv1k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#cached count files / modality\n",
        "\n",
        "# how many .npy slice files it contains and prints the counts\n",
        "\n",
        "from collections import Counter\n",
        "import glob, os\n",
        "\n",
        "mod_counts = {\n",
        "    mod: len(glob.glob(str(SLICE_DIR / mod / \"*.npy\")))\n",
        "\n",
        "    for mod in [\"t1\", \"t1ce\", \"t2\", \"flair\", \"mask\"]\n",
        "}\n",
        "print(\"Cached slice counts:\")\n",
        "\n",
        "for k, v in mod_counts.items():\n",
        "\n",
        "    print(f\"{k:>5}: {v:6,d}\")\n",
        "\n",
        "total_pairs = mod_counts[\"mask\"]\n",
        "\n",
        "assert all(v == total_pairs for k, v in mod_counts.items() if k != \"mask\"), \\\n",
        "    \"Mismatch between  the image and mask counts!\"\n",
        "\n",
        "print(f\"\\n All modalities aligned — total tumour-containing slices: {total_pairs:,}\")\n",
        "\n",
        "\"\"\"\n",
        "Cached slice counts:\n",
        "   t1: 15,273\n",
        " t1ce: 15,273\n",
        "   t2: 15,273\n",
        "flair: 15,273\n",
        " mask: 15,272\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "8O6q5MD7jchd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# a randome slice plot across all 5 arrfays\n",
        "\n",
        "import matplotlib.pyplot as plt, random, numpy as np, pathlib\n",
        "\n",
        "def show_cached_sample():\n",
        "    # pick one slice\n",
        "    tag_path = random.choice(list((SLICE_DIR / \"mask\").glob(\"*.npy\")))\n",
        "\n",
        "    tag = tag_path.stem.replace(\"_mask\", \"\") if tag_path.stem.endswith(\"_mask\") else tag_path.stem\n",
        "    pid, z = tag.split(\"_z\")\n",
        "\n",
        "    imgs = {}\n",
        "    for mod in [\"t1\", \"t1ce\", \"t2\", \"flair\", \"mask\"]:\n",
        "\n",
        "        imgs[mod] = np.load(SLICE_DIR / mod / f\"{tag}.npy\")\n",
        "\n",
        "    titles = [\"T1\", \"T1-CE\", \"T2\", \"FLAIR\", \"Mask\", \"Overlay\"]\n",
        "\n",
        "    # plot\n",
        "    plt.figure(figsize=(15,3))\n",
        "    for i, mod in enumerate([\"t1\",\"t1ce\",\"t2\",\"flair\",\"mask\"]):\n",
        "        plt.subplot(1,6,i+1)\n",
        "        plt.imshow(imgs[mod].T, cmap='gray' if mod!=\"mask\" else 'viridis', origin='lower')\n",
        "        plt.axis('off'); plt.title(titles[i])\n",
        "\n",
        "    # overlay\n",
        "    plt.subplot(1,6,6)\n",
        "    plt.imshow(imgs[\"t1ce\"].T, cmap='gray', origin='lower')\n",
        "    plt.imshow(imgs[\"mask\"].T, alpha=0.35, cmap='Reds', origin='lower')\n",
        "    plt.axis('off'); plt.title(titles[5])\n",
        "    plt.suptitle(f\"{pid}  |  axial slice z={int(z):03d}\")\n",
        "    plt.tight_layout(); plt.show()\n",
        "\n",
        "show_cached_sample()"
      ],
      "metadata": {
        "id": "IYN5zphCkGkG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Build slice list from intersection of all modalities\n",
        "import pathlib, random\n",
        "\n",
        "\"\"\"\n",
        "gathers the filenames in each modality folder..\n",
        "keeps only the slice IDs that appear in all five modalities\n",
        "groups those IDs by patient, shuffles the patients\n",
        " and then splits them patient-wise into an 80 % training set and a 20 % validation set\n",
        " so that no slices from the same patient leak across splits.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "DATA_DIR = pathlib.Path(\"/content/drive/MyDrive/964_project/segmentation/4modslices\")\n",
        "\n",
        "mods = [\"t1\", \"t1ce\", \"t2\", \"flair\", \"mask\"]\n",
        "\n",
        "# Collect IDs for each folder\n",
        "id_sets = {}\n",
        "for m in mods:\n",
        "    files = sorted((DATA_DIR / m).glob(\"*.npy\"))\n",
        "    id_sets[m] = {f.stem for f in files}\n",
        "\n",
        "# Intersection: only keep IDs that exist in every modality **and** mask\n",
        "\n",
        "common_ids = set.intersection(*id_sets.values())\n",
        "\n",
        "print(f\"Intersection slice count: {len(common_ids):,}  \"\n",
        "      f\"(dropped {len(id_sets['mask']) - len(common_ids)} orphan masks)\")\n",
        "\n",
        "# Group IDs by patient for leakage-free split\n",
        "\n",
        "def patient_id_from_slice(sid: str) -> str:\n",
        "    # Example sid: \"BraTS20_Training_033_z106\"  ->  \"BraTS20_Training_033\"\n",
        "    return \"_\".join(sid.split(\"_\")[:3])   # adjust if your naming differs\n",
        "\n",
        "patient_to_slices = {}\n",
        "for sid in common_ids:\n",
        "    pid = patient_id_from_slice(sid)\n",
        "    patient_to_slices.setdefault(pid, []).append(sid)\n",
        "\n",
        "patients = sorted(patient_to_slices.keys())\n",
        "random.seed(42)\n",
        "random.shuffle(patients)\n",
        "\n",
        "val_frac = 0.20 #20%\n",
        "n_val   = int(len(patients) * val_frac)\n",
        "val_patients   = set(patients[:n_val])\n",
        "train_patients = set(patients[n_val:])\n",
        "\n",
        "train_slice_ids = [sid for p in train_patients for sid in patient_to_slices[p]]\n",
        "val_slice_ids   = [sid for p in val_patients   for sid in patient_to_slices[p]]\n",
        "\n",
        "print(f\"\\nPatients → train: {len(train_patients)}, val: {len(val_patients)}\")\n",
        "print(f\"Slices   → train: {len(train_slice_ids):,}, val: {len(val_slice_ids):,}\")\n",
        "\n",
        "\"\"\"\n",
        "Intersection slice count: 15,272  (dropped 0 orphan masks)\n",
        "\n",
        "Patients → train: 258, val: 64\n",
        "Slices   → train: 12,128, val: 3,144\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "JVZtV-HHlUVa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#an Albumentations augmentation pipeline (random flips, 90-degree rotations,\n",
        "#brightness/contrast jitter) that is applied jointly to images and their masks\n",
        "\n",
        "train_transform = A.Compose([\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.VerticalFlip(p=0.5),\n",
        "    A.RandomRotate90(p=0.5),\n",
        "    A.RandomBrightnessContrast(p=0.5)\n",
        "], additional_targets={\"mask\":\"mask\"})\n",
        "\n"
      ],
      "metadata": {
        "id": "QmUVBizll7e2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BraTSSliceDS(Dataset):\n",
        "    mods = [\"t1\",\"t1ce\",\"t2\",\"flair\"]; mask_folder=\"mask\"\n",
        "\n",
        "    def __init__(self, root, ids, tf=None):\n",
        "        self.root, self.ids, self.tf = pathlib.Path(root), ids, tf\n",
        "\n",
        "    def __len__(self): return len(self.ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sid = self.ids[idx]\n",
        "        img  = np.stack([np.load(self.root/m/f\"{sid}.npy\", mmap_mode='r')\n",
        "                         for m in self.mods], -1)\n",
        "        mask = (np.load(self.root/self.mask_folder/f\"{sid}.npy\", mmap_mode='r')>0\n",
        "                ).astype(np.float32)[...,None]\n",
        "        if self.tf:\n",
        "            aug = self.tf(image=img, mask=mask); img, mask = aug[\"image\"], aug[\"mask\"]\n",
        "        img  = torch.from_numpy(img.transpose(2,0,1)).float()\n",
        "        mask = torch.from_numpy(mask.transpose(2,0,1)).float()\n",
        "        return img, mask\n",
        "\n",
        "batch = 8 #batch size=8\n",
        "\n",
        "train_ds = BraTSSliceDS(DATA_DIR, train_slice_ids, train_transform)\n",
        "val_ds   = BraTSSliceDS(DATA_DIR, val_slice_ids)\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch, shuffle=True,  num_workers=0, pin_memory=False)\n",
        "val_loader   = DataLoader(val_ds,   batch, shuffle=False, num_workers=0, pin_memory=False)\n",
        "\n",
        "# sanity fetch\n",
        "x,y = next(iter(train_loader))\n",
        "\n",
        "print(\" print batch :\", x.shape, y.shape, torch.unique(y))\n",
        "\n",
        "\"\"\"\n",
        "torch.Size([8, 4, 240, 240]) torch.Size([8, 1, 240, 240]) tensor([0., 1.])\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "qWVe6ZO3mD7_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " #Model (U-Net + ResNet50 encoder)\n",
        " \"\"\"\n",
        "builds a lightweight 2-D U-Net whose encoder re-uses an ImageNet-pretrained ResNet-50\n",
        "the first convolution is widened from 3 to 4 channels so it can ingest the four MRI modalities,\n",
        "and the original RGB weights are copied while the new fourth-channel kernel is initialised by the RGB mean.\n",
        "The decoder upsamples with bilinear interpolation and concatenates skip-features from each encoder stage,\n",
        "then a 1×1 conv maps the final 64-channel feature map to a single-channel probability mask followed by a sigmoid\n",
        " \"\"\"\n",
        "\n",
        "\"\"\"\n",
        "ResNet-50- its first conv expects 3-channel RGB,\n",
        "but our MRI input has four modalities, so we replace that layer with a 4-channel Conv2d.\n",
        "To retain as much pretrained signal as possible, we copy the original RGB kernels into the first three input planes and\n",
        "initialise the new fourth plane with the mean of those kernels; this lets the network start with sensible weights instead of random\n",
        "values while still accommodating the extra modality.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class UNetResNet50(nn.Module):\n",
        "    def __init__(self, pretrained=True):\n",
        "        super().__init__()\n",
        "        enc = torchvision.models.resnet50(weights='IMAGENET1K_V1' if pretrained else None)\n",
        "        #adapting first conv to 4-channels\n",
        "\n",
        "        old_conv = enc.conv1\n",
        "        new_conv = nn.Conv2d(4, old_conv.out_channels, 7, 2, 3, bias=False)\n",
        "        with torch.no_grad():\n",
        "            new_conv.weight[:, :3] = old_conv.weight\n",
        "            new_conv.weight[:, 3:] = old_conv.weight.mean(dim=1, keepdim=True)\n",
        "        enc.conv1 = new_conv\n",
        "        self.enc1 = nn.Sequential(enc.conv1, enc.bn1, enc.relu)\n",
        "        self.enc2 = nn.Sequential(enc.maxpool, enc.layer1)\n",
        "        self.enc3 = enc.layer2\n",
        "        self.enc4 = enc.layer3\n",
        "        self.enc5 = enc.layer4\n",
        "        def block(ic, oc):\n",
        "            return nn.Sequential(\n",
        "                nn.Conv2d(ic, oc, 3, padding=1), nn.BatchNorm2d(oc), nn.ReLU(inplace=True),\n",
        "                nn.Conv2d(oc, oc, 3, padding=1), nn.BatchNorm2d(oc), nn.ReLU(inplace=True)\n",
        "            )\n",
        "        self.dec4 = block(2048+1024, 1024)\n",
        "        self.dec3 = block(1024+512,  512)\n",
        "        self.dec2 = block(512 +256,  256)\n",
        "        self.dec1 = block(256 +64,    64)\n",
        "        self.final = nn.Conv2d(64,1,1)\n",
        "\n",
        "    def forward(self,x):\n",
        "        x1 = self.enc1(x)          #64 ×120×120\n",
        "        x2 = self.enc2(x1)         #256×60×60\n",
        "        x3 = self.enc3(x2)         #512×30×30\n",
        "        x4 = self.enc4(x3)         #1024×15×15\n",
        "        x5 = self.enc5(x4)         #2048×8×8\n",
        "        d4 = self.dec4(torch.cat([F.interpolate(x5, x4.shape[2:], mode='bilinear', align_corners=False), x4],1))\n",
        "        d3 = self.dec3(torch.cat([F.interpolate(d4, x3.shape[2:], mode='bilinear', align_corners=False), x3],1))\n",
        "        d2 = self.dec2(torch.cat([F.interpolate(d3, x2.shape[2:], mode='bilinear', align_corners=False), x2],1))\n",
        "        d1 = self.dec1(torch.cat([F.interpolate(d2, x1.shape[2:], mode='bilinear', align_corners=False), x1],1))\n",
        "        out= self.final(F.interpolate(d1, scale_factor=2, mode='bilinear', align_corners=False))\n",
        "        return torch.sigmoid(out)\n",
        "\n"
      ],
      "metadata": {
        "id": "1qkIK10Zm2OM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Loss, metric, optimiser\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = UNetResNet50(pretrained=True).to(device)\n",
        "\n",
        "bce = nn.BCELoss()\n",
        "def dice_loss(p,t,eps=1e-6):\n",
        "    p=t.view(p.size(0),-1); t=t.view(t.size(0),-1)\n",
        "    inter=(p*t).sum(1); union=p.sum(1)+t.sum(1)\n",
        "    return 1-((2*inter+eps)/(union+eps)).mean()\n",
        "def dice_score(p,t,eps=1e-6):\n",
        "    p=t.view(p.size(0),-1); t=t.view(t.size(0),-1)\n",
        "    inter=(p*t).sum(1); union=p.sum(1)+t.sum(1)\n",
        "    return ((2*inter+eps)/(union+eps)).mean().item()\n",
        "\n",
        "opt = torch.optim.AdamW(model.parameters(), lr=3e-4)\n"
      ],
      "metadata": {
        "id": "lAIDSuCinJ-x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, platform, os\n",
        "print(\"torch.cuda.is_available():\", torch.cuda.is_available())\n",
        "if torch.cuda.is_available():\n",
        "    print(\"CUDA device:\", torch.cuda.get_device_name(0))"
      ],
      "metadata": {
        "id": "O1Gp7dK4pXGf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imgs, masks = next(iter(train_loader))\n",
        "print(\"Unique mask values:\", torch.unique(masks))\n"
      ],
      "metadata": {
        "id": "aFHLB3qbpZuL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DATA_DIR stays on Drive\n",
        "DATA_DIR = \"/content/drive/MyDrive/964_project/segmentation/4modslices\"\n",
        "\n",
        "# --- rebuild datasets (no change) ---\n",
        "train_ds = BraTSSliceDS(DATA_DIR, train_slice_ids, train_transform)\n",
        "val_ds   = BraTSSliceDS(DATA_DIR, val_slice_ids)          # no aug\n",
        "\n",
        "# --- new loaders: 2 workers + pin_memory ---\n",
        "batch_size = 8\n",
        "train_loader = DataLoader(\n",
        "    train_ds, batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=2,          # <— 2 prefetch threads\n",
        "    pin_memory=True,        # speeds GPU transfer\n",
        "    drop_last=True\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    val_ds, batch_size,\n",
        "    shuffle=False,\n",
        "    num_workers=2,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "print(\"DataLoaders rebuilt with 2 workers.\")\n"
      ],
      "metadata": {
        "id": "ZsgxHoFIqDBx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "SRC=\"/content/drive/MyDrive/964_project/segmentation/4modslices\"\n",
        "DST=\"/content/slice_cache\"\n",
        "\n",
        "echo \"Copying slices to fast local storage …\"\n",
        "time rsync -ah --info=progress2 \"$SRC\"/ \"$DST\"/\n",
        "echo \"Done — data now in $DST\""
      ],
      "metadata": {
        "id": "dMFb16heqFBG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!du -sh /content/slice_cache           # total size copied so far\n",
        "!find /content/slice_cache -type f | wc -l   # number of files copied\n"
      ],
      "metadata": {
        "id": "pU4aDkukqNKt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#copying slices to content folder to speed up the tfraingng process\n",
        "%%bash\n",
        "SRC=\"/content/drive/MyDrive/964_project/segmentation/4modslices\"\n",
        "DST=\"/content/slice_cache\"\n",
        "\n",
        "echo \"Resuming copy …\"\n",
        "rsync -ah --info=progress2 \"$SRC\"/ \"$DST\"/\n",
        "echo \"Copy complete\""
      ],
      "metadata": {
        "id": "h-uwjaYKqQcD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pathlib\n",
        "DATA_DIR = pathlib.Path(\"/content/slice_cache\")"
      ],
      "metadata": {
        "id": "vTOTGXRKqbLC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pathlib, torch\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "#local\n",
        "DATA_DIR = pathlib.Path(\"/content/slice_cache\")\n",
        "\n",
        "#now recreate dagtset\n",
        "train_ds = BraTSSliceDS(DATA_DIR, train_slice_ids, train_transform)\n",
        "val_ds   = BraTSSliceDS(DATA_DIR, val_slice_ids)      # no aug for val\n",
        "\n",
        "#fast datalaoders\n",
        "batch_size = 8\n",
        "train_loader = DataLoader(train_ds, batch_size,\n",
        "                          shuffle=True,  num_workers=2,\n",
        "                          pin_memory=True, drop_last=True)\n",
        "val_loader   = DataLoader(val_ds,   batch_size,\n",
        "                          shuffle=False, num_workers=2,\n",
        "                          pin_memory=True)\n",
        "\n",
        "print(\"Local-SSD DataLoaders ready!!!\")\n"
      ],
      "metadata": {
        "id": "cd5Gu8mhqd3K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#training\n",
        "import torch, time, datetime, glob, os\n",
        "import pathlib\n",
        "\n",
        "ckpt_dir = pathlib.Path(DATA_DIR).parent / \"checkpoints\"\n",
        "ckpt_dir.mkdir(exist_ok=True)\n",
        "\n",
        "num_epochs = 50\n",
        "\n",
        "# -------- resume if a checkpoint exists --------\n",
        "ckpts = sorted(glob.glob(str(ckpt_dir/\"ep*.pt\")))\n",
        "start_ep, best_dice = 1, 0.\n",
        "if ckpts:\n",
        "    last = torch.load(ckpts[-1], map_location=device)\n",
        "    model.load_state_dict(last[\"model_state_dict\"])\n",
        "    opt.load_state_dict(last[\"optimizer_state_dict\"])\n",
        "    start_ep = last[\"epoch\"] + 1\n",
        "    best_dice = last[\"dice\"]\n",
        "    print(f\"Resumed from epoch {last['epoch']} (val dice {best_dice:.3f})\")\n",
        "\n",
        "def hms(sec): return str(datetime.timedelta(seconds=int(sec)))\n",
        "print(f\"{'Epoch':>5} | {'Time':>8} | {'TrainL':>7} | {'ValL':>7} | \"\n",
        "      f\"{'TrainD':>6} | {'ValD':>5}\")\n",
        "\n",
        "for epoch in range(start_ep, num_epochs+1):\n",
        "    t0=time.time(); model.train()\n",
        "    tl, td = 0., 0.\n",
        "    for b,(img,msk) in enumerate(train_loader,1):\n",
        "        img, msk = img.to(device), msk.to(device)\n",
        "        opt.zero_grad(); pred = model(img)\n",
        "        loss = bce(pred, msk) + dice_loss(pred, msk)\n",
        "        loss.backward(); opt.step()\n",
        "        tl += loss.item(); td += dice_score((pred>=0.5).float(), msk)\n",
        "        if b % 100 == 0:\n",
        "            print(f\"   batch {b}/{len(train_loader)}\")   # heartbeat\n",
        "    tl /= len(train_loader); td /= len(train_loader)\n",
        "\n",
        "    # ---- validation ----\n",
        "    model.eval(); vl, vd = 0., 0.\n",
        "    with torch.no_grad():\n",
        "        for img,msk in val_loader:\n",
        "            img, msk = img.to(device), msk.to(device)\n",
        "            pred = model(img)\n",
        "            vl += (bce(pred, msk) + dice_loss(pred, msk)).item()\n",
        "            vd += dice_score((pred>=0.5).float(), msk)\n",
        "    vl /= len(val_loader); vd /= len(val_loader)\n",
        "\n",
        "    print(f\"{epoch:5d} | {hms(time.time()-t0):>8} | {tl:7.4f} | {vl:7.4f} | \"\n",
        "          f\"{td:6.4f} | {vd:5.4f}\")\n",
        "\n",
        "    torch.save({'epoch':epoch, 'model_state_dict':model.state_dict(),\n",
        "                'optimizer_state_dict':opt.state_dict(), 'dice':vd},\n",
        "               ckpt_dir/f\"ep{epoch:02d}_dice{vd:.3f}.pt\")\n",
        "    if vd > best_dice:\n",
        "        best_dice = vd\n",
        "        torch.save(model.state_dict(),\n",
        "                   ckpt_dir/f\"best_dice{best_dice:.3f}_ep{epoch:02d}.pt\")\n",
        "        print(f\"   ✔︎ new best saved (dice={best_dice:.3f})\")\n",
        "\"\"\"\n",
        "\n",
        "batch 1400/1516\n",
        "   batch 1500/1516\n",
        "   50 |  0:01:47 |  0.1988 |  0.1056 | 0.8423 | 0.9188\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "lnHXZCb3qr5F"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}